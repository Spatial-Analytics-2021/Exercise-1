{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3028269b24eb026db04867c47b1b8c17",
     "grade": false,
     "grade_id": "cell-f96b031c8ba19946",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 1 - Programming assignment\n",
    "\n",
    "Exercise 1 includes four problems that you need to solve with programming. For each problem you need to modify the notebook by adding your own solutions. Remember to save and commit your changes locally, and push your changes to GitHub after each major change! Regular commits will help you to keep track of your changes (and revert them if needed). Pushing your work to GitHub will ensure that you don't lose any work in case your computer crashes (can happen!).\n",
    " \n",
    "An overview of the tasks:\n",
    "\n",
    " - read data into geopandas from different file formats\n",
    " - make a simple static and interactive visualizations of the datasets \n",
    " - conduct point pattern analysis by:\n",
    "     - creating a Kernel Density Estimation for given point dataset\n",
    "     - testing whether points are clustered based on Ripley's $G$, $F$ and $K$ function\n",
    " - give us an estimate about how much time you used for doing the exercise and optional feedback about it\n",
    " \n",
    "### Due date\n",
    "\n",
    "This exercise should be returned to your personal Github repository within **two weeks** after the first practical session (by Wednesday 23:59). Please notice that finishing the programming exercises can take significant amount of time (especially if you don't have yet much programming experience). Hence, **it is recommended that you start immediately working on them.**    \n",
    "      \n",
    "### Start your exercise in CSC Notebooks\n",
    "\n",
    "Before you can start programming, you need to launch the CSC Notebook instance and clone your Exercise repository there using Git. If you need help with this, [read the documentation on the course site](https://spatial-analytics.readthedocs.io/en/latest/lessons/L1/git-basics.html).\n",
    " \n",
    "### Hints \n",
    "\n",
    "If there are general questions arising from this exercise, we will add hints to the course website under [Exercise 1 description](https://spatial-analytics.readthedocs.io/en/latest/lessons/L1/exercise-1.html). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f2e3aad426fc75f43572a66e196fa70a",
     "grade": false,
     "grade_id": "cell-b877cc4325532e19",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problem 1 - Warm up (5 points)\n",
    "\n",
    "In the first task you should write code in which you:\n",
    " \n",
    " - download and initialize OpenStreetMap data reader for Helsinki Region using `pyrosm`\n",
    " - Read following datasets from the OSM:\n",
    " \n",
    "   1. Buildings\n",
    "   2. Roads\n",
    "   3. Administrative boundary for the city district where you live, e.g. \"Otaniemi\" (see [pyrosm docs](https://pyrosm.readthedocs.io/en/latest/basics.html#read-boundaries))\n",
    " \n",
    " - Select the buildings and roads that intersect with the given administrative boundary (district) \n",
    " - Reproject the selected buildings and roads to EPSG:3067 (ETRS-TM35FIN)\n",
    " - Visualize the reprojected buildings, roads and the administrative boundary and produce a map that pleases your eye (style is free). \n",
    "   - Add a title to your map\n",
    "   - If you want to use black background you can `import matplotlib.pyplot as plt` and specify `plt.style.use(\"dark_background\")`\n",
    "   - For example, the output could look like following:\n",
    " \n",
    "![](img/hoods-example.png)\n",
    "   \n",
    "\n",
    "Please write your solution to the cell below (remove the `raise NotImplementedError()` code). You can create new cells as well if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a58637371cf1e9572ac981a687ad46dd",
     "grade": true,
     "grade_id": "cell-20a61454de8d83b8",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "105805ebff3c88ad9df5c80806148a97",
     "grade": false,
     "grade_id": "cell-35e419921ae01d80",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problem 2  - Kernel Density Estimation (5 points)\n",
    "\n",
    "Study the Helsinki building fires point dataset (`Helsinki_building_fires_2008-2010.csv`) and conduct a Kernel Density Estimation map. For doing this you will need Python's `pandas`, `geopandas`, `seaborn`, `matplotlib` and `contextily` libraries. You should do following tasks:\n",
    "\n",
    "1. Read the data from `Helsinki_building_fires_2008-2010.csv` into pandas DataFrame (0.5 point)\n",
    "2. Generate a new `geometry` column into the DataFrame based on the coordinates in the `x_coord` and `y_coord` columns. For doing this, you should use a handy function from geopandas called `gpd.points_from_xy()` (see [docs](https://geopandas.org/docs/reference/api/geopandas.points_from_xy.html)) (1 point)\n",
    "3. Create a geopandas GeoDataFrame from the DataFrame and specify the Coordinate Reference System to be `\"EPSG:2393\"` using the `crs` parameter. (1 point)\n",
    "4. Re-project the data into WGS84 (EPSG:4326) using `to_crs()` function (0.5 point)\n",
    "5. Create a Kernel Density Estimation map(s) out of the points using `seaborn`'s `kde_plot()` function. Use `contextily` library to add a background map for the KDE. For reference/help, see [this section at Rey et al. 2021](https://geographicdata.science/book/notebooks/08_point_pattern_analysis.html#kernel-density-estimation-kde). The `kde_plot()` uses [scipy.stats_gaussian_kde()](https://docs.scipy.org/doc/scipy/reference/reference/generated/scipy.stats.gaussian_kde.html#scipy.stats.gaussian_kde) function under the hood, which includes automatic bandwidth selection (read more from [scipy docs](https://docs.scipy.org/doc/scipy/reference/reference/generated/scipy.stats.gaussian_kde.html#scipy.stats.gaussian_kde)). You can increase or decrease the amount of smoothing by using `bw_adjust` -parameter (the default value is 1). You can adjust the grid size (optional) using the parameter `gridsize` (the default value is 200). `gridsize` adjusts how many points/grids per dimension (x and y) are used to create the density surface. \n",
    "   - Try out how chaging the `bw_adjust` value influences the outcome (create at least two maps). Choose values between 0.25 and 2.0. (1 point)\n",
    "   - Describe verbally how chaning the `bw_adjust` influences the KDE surface. (1 point)\n",
    "   \n",
    "\n",
    "As a result (with same parameters as in Rey et al. 2021, see link above), you should have something like following (does not need to look exactly like this):\n",
    "\n",
    "![KDE Map](img/KDE_map.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "240f11f8708616ec785d651e066de774",
     "grade": true,
     "grade_id": "cell-56ac0e2b932bdb9d",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b2ee8b3a09852d535fbb3b3350ca2f2e",
     "grade": false,
     "grade_id": "cell-46e57154f088439f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problem 3 - Ripley's alphabets: Are the point patterns clustered? (9 points)\n",
    "\n",
    "Continue with the same Helsinki building fires dataset (you can use the same GeoDataFrame created in Problem 2). Next, you will study the point dataset for clustering by calculating Ripley's $G$, $F$ and $K$ functions. We provide you a function called `plot_Ripleys_test()` that you can use for producing the Ripley's $G$|$F$|$K$ curves against the Complete Spatial Random point process. You should do following tasks:\n",
    "\n",
    "1. Extract `x` and `y` coordinates into a variable called `coordinates` from the GeoDataFrame into a numpy array. You can get the coordinate columns as arrays by placing their column names as a list inside the square brackets and calling `.values` which will return the columns as numpy arrays (`data[[<list-of-column-names-here>]].values`). The first five items in the result should look like following (1 point): \n",
    "\n",
    "   - ```\n",
    "    array([[3106079.06347912, 6718552.22906183],\n",
    "           [3160614.99720049, 6661209.04893058],\n",
    "           [3245346.48042037, 6667679.82574259],\n",
    "           [3281300.31644782, 6687652.0851804 ],\n",
    "           [3328102.11312715, 6671726.3355373 ]])\n",
    "    ```\n",
    "2. Conduct Ripley's $G$ test based on the previous coordinates by using the `g_test()` function from `pointpats` library. As parameters, specify `support=40` which will create 40 \"sample points\" at different distances, and specify that we want to keep the simulation results (for CSR) by adding `keep_simulations=True`, and specify that the number of simulations is 1000 using `n_simulations` -parameter. Store the result of the test into a variable called `G` (1 point).\n",
    "\n",
    "3. Visualize the result from Ripley's $G$ test by passing the variable `G` into the function `plot_Ripleys_test()` that we have provided for you below. Give your plot a descriptive title. The end result should look something like below (1 point):\n",
    "![Ripley's G](img/ripleys_g.png)\n",
    "\n",
    "4. **How would you interpret the result from $G$ test?** Describe the resulting graph and explain whether the point pattern seem to be clustered or not. Provide explanation why you end up in your conclusions. (1 point)\n",
    "\n",
    "5. In a similar manner as in steps 2 and 3, conduct Ripley's $F$ test based on the coordinates by using the `f_test()` function from `pointpats` library. Use the same parameters as in step 2. Store the result of the test into a variable called `F` and visualize the result using `plot_Ripleys_test()`. (1 point). The result should look something like below:\n",
    "\n",
    "![Ripley's F](img/ripleys_F.png)\n",
    "\n",
    "6. **How would you interpret the result from $F$ test?** Describe the resulting graph and explain whether the point pattern seem to be clustered or not. Provide explanation why you end up in your conclusions. (1 point)\n",
    "\n",
    "7. In a similar manner as in steps 2 and 3, conduct Ripley's $K$ test based on the coordinates by using the `k_test()` function from `pointpats` library. Use the same parameters as in step 2. Store the result of the test into a variable called `K` and visualize the result using `plot_Ripleys_test()`. (1 point). The result should look something like below:\n",
    "\n",
    "![Ripley's K](img/ripleys_K.png)\n",
    "\n",
    "8. **How would you interpret the result from $K$ test?** Describe the resulting graph and explain whether the point pattern seem to be clustered or not. Provide explanation why you end up in your conclusions. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5cace2aacac53b359ce236733b7adaa0",
     "grade": true,
     "grade_id": "cell-5e706ea9cc7a5472",
     "locked": false,
     "points": 9,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_Ripleys_test(test, \n",
    "                      coordinates,\n",
    "                      title=\"\", \n",
    "                      xlabel=\"distance\", \n",
    "                      ylabel='% of nearest neighbor\\ndistances shorter',\n",
    "                      xlim=None,\n",
    "                      ):\n",
    "    \"\"\"\n",
    "    Helper function to plot results from Ripley's tests. \n",
    "    Modified after Rey, Arribas-Bel & Wolf (2021). Geographic Data Science with Python.\n",
    "    \"\"\"\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    f,ax = plt.subplots(1,2,figsize=(9,3), \n",
    "                        gridspec_kw=dict(width_ratios=(6,3)))\n",
    "    \n",
    "    # Plot the simulations with thin lines\n",
    "    ax[0].plot(test.support, test.simulations.T, color='k', alpha=.01)\n",
    "    \n",
    "    # Show the average of simulations\n",
    "    ax[0].plot(test.support, np.median(test.simulations, axis=0), color='cyan', \n",
    "             label='median simulation (CSR)')\n",
    "\n",
    "\n",
    "    # Show the observed pattern's G|F|K function\n",
    "    ax[0].plot(test.support, test.statistic, label = 'observed', color='red')\n",
    "\n",
    "    # Clean labels and axes\n",
    "    ax[0].set_xlabel(xlabel)\n",
    "    ax[0].set_ylabel(ylabel)\n",
    "    ax[0].legend()\n",
    "    \n",
    "    # If xlim is provided modify accordingly\n",
    "    if xlim is not None:\n",
    "        ax[0].set_xlim(0, xlim)\n",
    "    else:\n",
    "        ax[0].set_xlim(0, round(test.support.max(), 0))\n",
    "        \n",
    "    # Set title for the plot\n",
    "    ax[0].set_title(title)\n",
    "\n",
    "    # Plot the point pattern \n",
    "    ax[1].scatter(*coordinates.T)\n",
    "\n",
    "    # Clean up labels and axes from the point pattern\n",
    "    ax[1].set_xticks([])\n",
    "    ax[1].set_yticks([])\n",
    "    ax[1].set_xticklabels([])\n",
    "    ax[1].set_yticklabels([])\n",
    "    ax[1].set_title('Pattern')\n",
    "    f.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e1714f24eb191851f8d1465365a595ed",
     "grade": false,
     "grade_id": "cell-959f679e2a3744dc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Problem 4 - How long did it take? Optional feedback (1 point)\n",
    "\n",
    "To help developing the exercises, and understanding the time that it took for you to finish the Exercise, please provide an estimate of how many hours you spent for doing this exercise?\n",
    "\n",
    " - I spent approximately this many hours: **X hours**\n",
    " \n",
    "In addition, if you would like to give any feedback about the exercise (optional), please provide it below:\n",
    "\n",
    " - My feedback: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
